{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiqubit and Binaryoutput QML-Hybrid.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Jii2mfodcl",
        "outputId": "dea77f90-a9d7-4dd9-a129-814668371213"
      },
      "source": [
        "!pip install qiskit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.6/dist-packages (0.23.5)\n",
            "Requirement already satisfied: qiskit-aqua==0.8.2 in /usr/local/lib/python3.6/dist-packages (from qiskit) (0.8.2)\n",
            "Requirement already satisfied: qiskit-aer==0.7.4 in /usr/local/lib/python3.6/dist-packages (from qiskit) (0.7.4)\n",
            "Requirement already satisfied: qiskit-ignis==0.5.2 in /usr/local/lib/python3.6/dist-packages (from qiskit) (0.5.2)\n",
            "Requirement already satisfied: qiskit-ibmq-provider==0.11.1 in /usr/local/lib/python3.6/dist-packages (from qiskit) (0.11.1)\n",
            "Requirement already satisfied: qiskit-terra==0.16.4 in /usr/local/lib/python3.6/dist-packages (from qiskit) (0.16.4)\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.3.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (53.0.0)\n",
            "Requirement already satisfied: quandl in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (3.6.0)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.4.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.7.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (5.4.8)\n",
            "Requirement already satisfied: retworkx>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.7.2)\n",
            "Requirement already satisfied: dlx in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.1.5)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.1.55)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (2.10.0)\n",
            "Requirement already satisfied: docplex==2.15.194 in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (2.15.194)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.8)\n",
            "Requirement already satisfied: cython>=0.27.1 in /usr/local/lib/python3.6/dist-packages (from qiskit-aer==0.7.4->qiskit) (0.29.21)\n",
            "Requirement already satisfied: pybind11>=2.4 in /usr/local/lib/python3.6/dist-packages (from qiskit-aer==0.7.4->qiskit) (2.6.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from qiskit-ignis==0.5.2->qiskit) (2.5)\n",
            "Requirement already satisfied: websockets>=8 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (2.8.1)\n",
            "Requirement already satisfied: nest-asyncio!=1.1.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (2.23.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.24.3)\n",
            "Requirement already satisfied: requests-ntlm>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.1.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.6.0)\n",
            "Requirement already satisfied: python-constraint>=1.4 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.10 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.15.0)\n",
            "Requirement already satisfied: ply>=3.10 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (3.11)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (0.3.3)\n",
            "Requirement already satisfied: contextvars>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->qiskit-aqua==0.8.2->qiskit) (1.0.0)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from quandl->qiskit-aqua==0.8.2->qiskit) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from quandl->qiskit-aqua==0.8.2->qiskit) (1.15.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl->qiskit-aqua==0.8.2->qiskit) (8.7.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy>=1.3->qiskit-aqua==0.8.2->qiskit) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->qiskit-aqua==0.8.2->qiskit) (2018.9)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from yfinance->qiskit-aqua==0.8.2->qiskit) (4.6.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance->qiskit-aqua==0.8.2->qiskit) (0.0.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->qiskit-ignis==0.5.2->qiskit) (4.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2.10)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.6/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (3.4.6)\n",
            "Requirement already satisfied: ntlm-auth>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (1.5.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.4; python_version < \"3.7\"->qiskit-terra==0.16.4->qiskit) (0.15)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E61VulyirRGK"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.autograd import Function\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import qiskit\r\n",
        "from qiskit.visualization import *\r\n",
        "from qiskit import ClassicalRegister"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45yi7euyyRNZ"
      },
      "source": [
        "QC_outputs = ['000', '001', '010', '011', '100', '101', '110', '111']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-3MTFuvrdQJ"
      },
      "source": [
        "# Defines the quantum circuit so we can use it (since hybrids have quantum)\r\n",
        "class QuantumCircuit:\r\n",
        "  #This is the initialization\r\n",
        "  def __init__(self, n_qubits, backend, shots):\r\n",
        "    #Define how many lanes we want\r\n",
        "    self._circuit = qiskit.QuantumCircuit(n_qubits)\r\n",
        "\r\n",
        "    #Just a list of 0 to the number of qubits... Just useful so we can just define the circuit (with all it's little parts super quickly)\r\n",
        "    all_qubits = [i for i in range(n_qubits)]\r\n",
        "    #Kind of like a placeholder variable so we can fill it in later\r\n",
        "    self.theta_0 = qiskit.circuit.Parameter('theta0')\r\n",
        "    self.theta_1 = qiskit.circuit.Parameter('theta1')\r\n",
        "    self.theta_2 = qiskit.circuit.Parameter('theta2')\r\n",
        "    self.theta_3 = qiskit.circuit.Parameter('theta3')\r\n",
        "    self.theta_4 = qiskit.circuit.Parameter('theta4')\r\n",
        "    self.theta_5 = qiskit.circuit.Parameter('theta5')\r\n",
        "    self.theta_6 = qiskit.circuit.Parameter('theta6')\r\n",
        "\r\n",
        "    #Shove in the Hardav gate, a barrier (visual), and a rotation about the y plane of theta degrees\r\n",
        "    self._circuit.h(all_qubits)\r\n",
        "    self._circuit.barrier()\r\n",
        "    self._circuit.ry(self.theta_0, all_qubits)\r\n",
        "    #Now comes the custom thing for 3 specifically\r\n",
        "    self._circuit.cz(0,1)\r\n",
        "    self._circuit.cz(1,2)\r\n",
        "    self._circuit.ry(self.theta_1, 0)\r\n",
        "    self._circuit.ry(self.theta_2, 1)\r\n",
        "    self._circuit.ry(self.theta_3, 2)\r\n",
        "    self._circuit.cz(0,1)\r\n",
        "    self._circuit.cz(1,2)\r\n",
        "    self._circuit.ry(self.theta_4, 0)\r\n",
        "    self._circuit.ry(self.theta_5, 1)\r\n",
        "    self._circuit.ry(self.theta_6, 2)\r\n",
        "\r\n",
        "    self._circuit.measure_all()\r\n",
        "\r\n",
        "    #save these varaibles for later so we don't have to call them again during the forwarding\r\n",
        "    self.backend = backend\r\n",
        "    self.shots = shots\r\n",
        "  \r\n",
        "  #forwarding through the quantum circuit\r\n",
        "  def run(self, thetas):\r\n",
        "    #prep the execution. Link to circuit, Define backend and number of shots... And then fill in the placeholder variable (theta) with the thing we pass through when we forward\r\n",
        "    job = qiskit.execute(self._circuit,\r\n",
        "                         self.backend,\r\n",
        "                         shots = self.shots,\r\n",
        "                         parameter_binds = [{self.theta_0: thetas[0],\r\n",
        "                                             self.theta_1: thetas[1],\r\n",
        "                                             self.theta_2: thetas[2],\r\n",
        "                                             self.theta_3: thetas[3],\r\n",
        "                                             self.theta_4: thetas[4],\r\n",
        "                                             self.theta_5: thetas[5],\r\n",
        "                                             self.theta_6: thetas[6],}]) # Might have to change this when multi layer\r\n",
        "    \r\n",
        "    #execution\r\n",
        "    counts = job.result().get_counts(self._circuit)\r\n",
        "\r\n",
        "    expects = np.zeros(8)\r\n",
        "    for k in range(8):\r\n",
        "      key = QC_outputs[k]\r\n",
        "      perc = counts.get(key, 0) /self.shots\r\n",
        "      expects[k] = perc\r\n",
        "    return expects"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toApC567z76D"
      },
      "source": [
        "sim = qiskit.Aer.get_backend('qasm_simulator')\r\n",
        "\r\n",
        "test_circuit = QuantumCircuit(3, sim, 100000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "HKZ-V5ek0Kqm",
        "outputId": "48691e3f-bd9a-4a86-eef4-5f9d35f525a5"
      },
      "source": [
        "test_circuit.run([1,2,1,4,5,6,8])\r\n",
        "\r\n",
        "test_circuit._circuit.draw()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌────────────┐   ┌────────────┐                 ┌────────────┐»\n",
              "   q_0: ┤ H ├─░─┤ RY(theta0) ├─■─┤ RY(theta1) ├───────────────■─┤ RY(theta4) ├»\n",
              "        ├───┤ ░ ├────────────┤ │ └────────────┘┌────────────┐ │ └────────────┘»\n",
              "   q_1: ┤ H ├─░─┤ RY(theta0) ├─■───────■───────┤ RY(theta2) ├─■───────■───────»\n",
              "        ├───┤ ░ ├────────────┤         │       ├────────────┤         │       »\n",
              "   q_2: ┤ H ├─░─┤ RY(theta0) ├─────────■───────┤ RY(theta3) ├─────────■───────»\n",
              "        └───┘ ░ └────────────┘                 └────────────┘                 »\n",
              "meas: 3/══════════════════════════════════════════════════════════════════════»\n",
              "                                                                              »\n",
              "«                       ░ ┌─┐      \n",
              "«   q_0: ───────────────░─┤M├──────\n",
              "«        ┌────────────┐ ░ └╥┘┌─┐   \n",
              "«   q_1: ┤ RY(theta5) ├─░──╫─┤M├───\n",
              "«        ├────────────┤ ░  ║ └╥┘┌─┐\n",
              "«   q_2: ┤ RY(theta6) ├─░──╫──╫─┤M├\n",
              "«        └────────────┘ ░  ║  ║ └╥┘\n",
              "«meas: 3/══════════════════╩══╩══╩═\n",
              "«                          0  1  2 </pre>"
            ],
            "text/plain": [
              "        ┌───┐ ░ ┌────────────┐   ┌────────────┐                 ┌────────────┐»\n",
              "   q_0: ┤ H ├─░─┤ RY(theta0) ├─■─┤ RY(theta1) ├───────────────■─┤ RY(theta4) ├»\n",
              "        ├───┤ ░ ├────────────┤ │ └────────────┘┌────────────┐ │ └────────────┘»\n",
              "   q_1: ┤ H ├─░─┤ RY(theta0) ├─■───────■───────┤ RY(theta2) ├─■───────■───────»\n",
              "        ├───┤ ░ ├────────────┤         │       ├────────────┤         │       »\n",
              "   q_2: ┤ H ├─░─┤ RY(theta0) ├─────────■───────┤ RY(theta3) ├─────────■───────»\n",
              "        └───┘ ░ └────────────┘                 └────────────┘                 »\n",
              "meas: 3/══════════════════════════════════════════════════════════════════════»\n",
              "                                                                              »\n",
              "«                       ░ ┌─┐      \n",
              "«   q_0: ───────────────░─┤M├──────\n",
              "«        ┌────────────┐ ░ └╥┘┌─┐   \n",
              "«   q_1: ┤ RY(theta5) ├─░──╫─┤M├───\n",
              "«        ├────────────┤ ░  ║ └╥┘┌─┐\n",
              "«   q_2: ┤ RY(theta6) ├─░──╫──╫─┤M├\n",
              "«        └────────────┘ ░  ║  ║ └╥┘\n",
              "«meas: 3/══════════════════╩══╩══╩═\n",
              "«                          0  1  2 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aVKFvxS0PPZ"
      },
      "source": [
        "#This class defines what our hybrid layer does. It allows it to go forward, and also backprop\r\n",
        "class HybridFunction(Function):\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def forward(ctx, input, quantum_circuit, shift):\r\n",
        "    ctx.shift = shift\r\n",
        "    ctx.quantum_circuit = quantum_circuit\r\n",
        "\r\n",
        "    parameter = []\r\n",
        "\r\n",
        "    for x in input:\r\n",
        "      for y in x:\r\n",
        "        parameter.append(float(y))\r\n",
        "    # print(parameter)\r\n",
        "\r\n",
        "    #Aka we run the input into our circuit\r\n",
        "    expectation_z = ctx.quantum_circuit.run(parameter) #Might need to change this when have multi-layer\r\n",
        "    #Shoves to pytorch tesnor\r\n",
        "    result = torch.tensor([expectation_z])\r\n",
        "    #Save the input and result for backpropagation\r\n",
        "    ctx.save_for_backward(input,result)\r\n",
        "    #return output\r\n",
        "    return result\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def backward(ctx, grad_output):\r\n",
        "    #Regrabing the input and the output\r\n",
        "    input, expectation_z = ctx.saved_tensors\r\n",
        "    # input_list = np.array(input.tolist())\r\n",
        "    # print(input)\r\n",
        "\r\n",
        "    input_list = list(input)[0]\r\n",
        "    # print(input_list)\r\n",
        "\r\n",
        "    #AKA if we take our inputs and just add/subtract a tiny amount\r\n",
        "    # shift_right = input_list + np.ones(input_list.shape) * ctx.shift\r\n",
        "    # shift_left = input_list - np.ones(input_list.shape) * ctx.shift\r\n",
        "    # print(shift_right)\r\n",
        "    # print(shift_left)\r\n",
        "\r\n",
        "    #A list of all the gradients\r\n",
        "    gradients = torch.Tensor()\r\n",
        "\r\n",
        "    #We're going to go through the inputs and then calculate the gradient for each one\r\n",
        "    for i in range(7):\r\n",
        "      shift_right = np.array(input_list.detach().clone())\r\n",
        "      shift_left = np.array(input_list.detach().clone())\r\n",
        "      shift_right[i] = shift_right[i] + ctx.shift\r\n",
        "      shift_left[i] = shift_left[i] - ctx.shift\r\n",
        "\r\n",
        "      #So we take the shifted ones and just compute it \r\n",
        "      expectation_right = ctx.quantum_circuit.run(shift_right)\r\n",
        "      expectation_left  = ctx.quantum_circuit.run(shift_left)\r\n",
        "      #Gradient = appox the difference (division by 2*shift isn't necessary since it'll just be a scaled version (which can be counteracted by lr))\r\n",
        "      gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\r\n",
        "      #Append the gradient to the meta list\r\n",
        "      gradients  = torch.cat((gradients, gradient.float()))\r\n",
        "      # print(gradient.shape)\r\n",
        "      # print(gradients.shape)\r\n",
        "    \r\n",
        "    #Turn it into np and transpose it\r\n",
        "    # print(gradients.shape)\r\n",
        "\r\n",
        "    # gradients = np.array(gradients)\r\n",
        "    # print(gradients)\r\n",
        "    result = torch.Tensor(gradients)\r\n",
        "    result = result.float()\r\n",
        "    result = result.T\r\n",
        "\r\n",
        "    # gradients = gradients.T\r\n",
        "    # print(result.shape)\r\n",
        "    Fixer = grad_output.float()\r\n",
        "    Fixer = Fixer.T\r\n",
        "    # print(Fixer.shape)\r\n",
        "\r\n",
        "    h = result * Fixer\r\n",
        "    # print(h.shape)\r\n",
        "    #then return it for backprop\r\n",
        "    return h, None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u08J7bVzQHum"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv5A7QC8ul2R"
      },
      "source": [
        "#This defines the acutal thing that we're shoving into the NN\r\n",
        "class Hybrid(nn.Module):\r\n",
        "  #initialization\r\n",
        "  def __init__(self, backend, shots, shift):\r\n",
        "    super(Hybrid, self).__init__()\r\n",
        "    #Define the real quantum circuit that we'll be using for our thing\r\n",
        "    self.quantum_circuit = QuantumCircuit(3, backend, shots)\r\n",
        "    #Save this guy for alter\r\n",
        "    self.shift = shift\r\n",
        "  \r\n",
        "  #When forwarding\r\n",
        "  def forward(self, input):\r\n",
        "    return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrvo6muavKEb"
      },
      "source": [
        "#Now we just define the data stuff\r\n",
        "\r\n",
        "n_samples = 1000\r\n",
        "\r\n",
        "X_train = datasets.MNIST(root='./data', train=True, download=True,\r\n",
        "                         transform=transforms.Compose([transforms.ToTensor()]))\r\n",
        "\r\n",
        "# Leaving only labels 0 and 1 \r\n",
        "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \r\n",
        "                np.where(X_train.targets == 1)[0][:n_samples])\r\n",
        "\r\n",
        "X_train.data = X_train.data[idx]\r\n",
        "X_train.targets = X_train.targets[idx]\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_NW21jbvWmb"
      },
      "source": [
        "n_samples = 1000\r\n",
        "\r\n",
        "X_test = datasets.MNIST(root='./data', train=False, download=True,\r\n",
        "                        transform=transforms.Compose([transforms.ToTensor()]))\r\n",
        "\r\n",
        "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \r\n",
        "                np.where(X_test.targets == 1)[0][:n_samples])\r\n",
        "\r\n",
        "X_test.data = X_test.data[idx]\r\n",
        "X_test.targets = X_test.targets[idx]\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaX_00tvZt0"
      },
      "source": [
        "#The actual one\r\n",
        "class Net(nn.Module):\r\n",
        "  #Initialization\r\n",
        "  def __init__(self):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    #Defining all the classical layers\r\n",
        "    self.classical = nn.Sequential(\r\n",
        "        nn.Conv2d(1,6,5),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2),\r\n",
        "        nn.Conv2d(6,16,5),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2),\r\n",
        "        nn.Dropout()\r\n",
        "    )\r\n",
        "    #Defining the middel part\r\n",
        "    self.middel = nn.Sequential(\r\n",
        "        nn.Linear(256,64),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(64,7))\r\n",
        "    #Definign the quantum part\r\n",
        "    self.quantum = Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 1000, np.pi / 2)\r\n",
        "\r\n",
        "    #Defining part 2 of classical (to bring it back down to 1 output)\r\n",
        "    self.end = nn.Sequential(\r\n",
        "        nn.Linear(8,1),\r\n",
        "        nn.Sigmoid()\r\n",
        "    )\r\n",
        "  \r\n",
        "  #For whenever we pass stuff through it\r\n",
        "  def forward(self,x):\r\n",
        "    #Pass it through each one\r\n",
        "    x = self.classical(x)\r\n",
        "    x = x.view(1, -1)\r\n",
        "    x = self.middel(x)\r\n",
        "    theta = x\r\n",
        "    # print(x)\r\n",
        "    x = self.quantum(x)\r\n",
        "    # print(x)\r\n",
        "    x = self.end(x.float())\r\n",
        "    x = x.view(1, -1)\r\n",
        "    # print(x)\r\n",
        "    return torch.cat((x, 1-x), -1), theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfzokPbzrYr"
      },
      "source": [
        "#Define the model, optimzier and loss function\r\n",
        "model = Net()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "loss_func = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "#Define the epochs and the list (where we plot) the losses\r\n",
        "epochs = 1\r\n",
        "loss_list = []\r\n",
        "thetas = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JplxyckxbMoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7130019-df15-4f0b-f132-ba89dd51f18c"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (classical): Sequential(\n",
              "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (middel): Sequential(\n",
              "    (0): Linear(in_features=256, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=7, bias=True)\n",
              "  )\n",
              "  (quantum): Hybrid()\n",
              "  (end): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYtKtfvBQKco"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmy5Eh710GPj",
        "outputId": "54da807a-7105-442a-9f0b-5bbaddf6491c"
      },
      "source": [
        "#Training mode\r\n",
        "model.train()\r\n",
        "for epoch in range(epochs):\r\n",
        "  #So we can shove it on the loss graph\r\n",
        "  total_loss = []\r\n",
        "  #Go through the dataloader\r\n",
        "  for image, label in train_loader:\r\n",
        "    #Set the gradient back to 0\r\n",
        "    optimizer.zero_grad()\r\n",
        "    #Shove the image through the model\r\n",
        "    # try:\r\n",
        "    prediction,theta = model(image)\r\n",
        "    #Get the loss\r\n",
        "    # print(label)\r\n",
        "    # print(prediction)\r\n",
        "    loss = loss_func(prediction, label)\r\n",
        "    #Compute the gradients\r\n",
        "    loss.backward()\r\n",
        "    #Update parameters\r\n",
        "    optimizer.step()\r\n",
        "    #Save theta\r\n",
        "    thetas.append(theta)\r\n",
        "    #Add this loss to the total\r\n",
        "    total_loss.append(loss.item())\r\n",
        "    # except:\r\n",
        "    #   continue\r\n",
        "  \r\n",
        "  #Shove total loss of epoch to the total loss of the model\r\n",
        "  loss_list.append(sum(total_loss) / len(total_loss))\r\n",
        "  #Print some readout so we know it's working\r\n",
        "  print(loss_list[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.519454716309905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-M30HrQv0cor",
        "outputId": "a985afb4-88bf-4e07-ecf1-c3fb4ed38fe1"
      },
      "source": [
        "plt.plot(loss_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3873037e48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOiUlEQVR4nO3cf6hf913H8edrCakrZS5d72rWxN1MC7pKmfRLZOBk/ugWBdOxihaFNdNSZYaCUjBSwZn5h+sciqwgoRSioIlGBrdOjNlwuD/8kW9m7JrWLLeZIzet7q7ZxDpMCHv7xz2p31y/6f3ee7/3fnM/ez7gcM/5fD7n3Pc7F1738D3nJlWFJKldr5t0AZKktWXQS1LjDHpJapxBL0mNM+glqXGbJ13AYrfddltNT09PugxJ2lBOnjz51aqaGjZ3wwX99PQ0/X5/0mVI0oaS5MvXm/OjG0lqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0bKeiT7E5yJslskv1D5vcmmU9yqtseWjT/hiRzST4xrsIlSaPZvNSCJJuAJ4B7gTngRJKZqnpu0dIjVbXvOpf5CPB3q6pUkrQio9zR7wJmq+pcVV0GDgP3jfoNktwD3A78zcpKlCStxihBfwdwfuB4rhtb7P4kzyQ5mmQHQJLXAR8HHn2tb5Dk4ST9JP35+fkRS5ckjWJcD2OfBqar6m7gOHCoG/8Q8FdVNfdaJ1fVwarqVVVvampqTCVJkmCEz+iBC8COgePt3dirqurlgcMngce7/XcC70ryIeAWYEuSV6rq/z3QlSStjVGC/gRwZ5KdLAT8A8DPDi5Isq2qXuoO9wDPA1TVzw2s2Qv0DHlJWl9LBn1VXUmyDzgGbAKeqqrTSQ4A/aqaAR5Jsge4AlwE9q5hzZKkZUhVTbqGa/R6ver3+5MuQ5I2lCQnq6o3bM6/jJWkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatxIQZ9kd5IzSWaT7B8yvzfJfJJT3fZQN/7WJJ/vxk4n+aVxNyBJem2bl1qQZBPwBHAvMAecSDJTVc8tWnqkqvYtGnsJeGdVXUpyC/Bsd+6L4yhekrS0Ue7odwGzVXWuqi4Dh4H7Rrl4VV2uqkvd4U0jfj9J0hiNErx3AOcHjue6scXuT/JMkqNJdlwdTLIjyTPdNT467G4+ycNJ+kn68/Pzy2xBkvRaxnWH/TQwXVV3A8eBQ1cnqup8N/7dwINJbl98clUdrKpeVfWmpqbGVJIkCUYL+gvAjoHj7d3Yq6rq5YGPaJ4E7ll8ke5O/lngXSsrVZK0EqME/QngziQ7k2wBHgBmBhck2TZwuAd4vhvfnuT13f5W4AeBM+MoXJI0miXfuqmqK0n2AceATcBTVXU6yQGgX1UzwCNJ9gBXgIvA3u707wU+nqSAAL9bVV9Ygz4kSdeRqpp0Ddfo9XrV7/cnXYYkbShJTlZVb9icrztKUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDVupKBPsjvJmSSzSfYPmd+bZD7JqW57qBt/R5K/T3I6yTNJfmbcDUiSXtvmpRYk2QQ8AdwLzAEnksxU1XOLlh6pqn2Lxr4BfKCqziZ5C3AyybGq+vo4ipckLW2UO/pdwGxVnauqy8Bh4L5RLl5VX6yqs93+i8BXgKmVFitJWr5Rgv4O4PzA8Vw3ttj93cczR5PsWDyZZBewBXhhyNzDSfpJ+vPz8yOWLkkaxbgexj4NTFfV3cBx4NDgZJJtwB8DH6yqby4+uaoOVlWvqnpTU97wS9I4jRL0F4DBO/Tt3dirqurlqrrUHT4J3HN1LskbgE8Bj1XVP6yuXEnSco0S9CeAO5PsTLIFeACYGVzQ3bFftQd4vhvfAnwS+KOqOjqekiVJy7HkWzdVdSXJPuAYsAl4qqpOJzkA9KtqBngkyR7gCnAR2Nud/tPADwFvSnJ1bG9VnRpvG5Kk60lVTbqGa/R6ver3+5MuQ5I2lCQnq6o3bM6/jJWkxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJatxIQZ9kd5IzSWaT7B8yvzfJfJJT3fbQwNxfJ/l6kr8cZ+GSpNFsXmpBkk3AE8C9wBxwIslMVT23aOmRqto35BIfA24GfnG1xUqSlm+UO/pdwGxVnauqy8Bh4L5Rv0FVfQb4rxXWJ0lapVGC/g7g/MDxXDe22P1JnklyNMmO5RSR5OEk/ST9+fn55ZwqSVrCuB7GPg1MV9XdwHHg0HJOrqqDVdWrqt7U1NSYSpIkwWhBfwEYvEPf3o29qqperqpL3eGTwD3jKU+StFqjBP0J4M4kO5NsAR4AZgYXJNk2cLgHeH58JUqSVmPJt26q6kqSfcAxYBPwVFWdTnIA6FfVDPBIkj3AFeAisPfq+Uk+B3wPcEuSOeAXqurY+FuRJA2Tqpp0Ddfo9XrV7/cnXYYkbShJTlZVb9icfxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4kYI+ye4kZ5LMJtk/ZH5vkvkkp7rtoYG5B5Oc7bYHx1m8JGlpm5dakGQT8ARwLzAHnEgyU1XPLVp6pKr2LTr3VuA3gR5QwMnu3K+NpXpJ0pJGuaPfBcxW1bmqugwcBu4b8frvBY5X1cUu3I8Du1dWqiRpJUYJ+juA8wPHc93YYvcneSbJ0SQ7lnNukoeT9JP05+fnRyxdkjSKcT2MfRqYrqq7WbhrP7Sck6vqYFX1qqo3NTU1ppIkSTBa0F8Adgwcb+/GXlVVL1fVpe7wSeCeUc+VJK2tUYL+BHBnkp1JtgAPADODC5JsGzjcAzzf7R8D3pNka5KtwHu6MUnSOlnyrZuqupJkHwsBvQl4qqpOJzkA9KtqBngkyR7gCnAR2NudezHJR1j4ZQFwoKourkEfkqTrSFVNuoZr9Hq96vf7ky5DkjaUJCerqjdszr+MlaTGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqXKpq0jVcI8k88OVJ17ECtwFfnXQR68yevzXY88bw1qqaGjZxwwX9RpWkX1W9Sdexnuz5W4M9b3x+dCNJjTPoJalxBv34HJx0ARNgz98a7HmD8zN6SWqcd/SS1DiDXpIaZ9AvQ5JbkxxPcrb7uvU66x7s1pxN8uCQ+Zkkz659xau3mp6T3JzkU0n+NcnpJL+zvtWPLsnuJGeSzCbZP2T+piRHuvl/TDI9MPfr3fiZJO9dz7pXY6U9J7k3yckkX+i+/sh6175Sq/k5d/PfmeSVJI+uV81jUVVuI27A48D+bn8/8NEha24FznVft3b7Wwfm3w/8CfDspPtZ656Bm4Ef7tZsAT4H/PikexpS/ybgBeBtXZ3/Arx90ZoPAX/Y7T8AHOn2396tvwnY2V1n06R7WuOevx94S7f/fcCFSfez1j0PzB8F/hx4dNL9LGfzjn557gMOdfuHgPcNWfNe4HhVXayqrwHHgd0ASW4BfhX47XWodVxW3HNVfaOq/hagqi4Dnwe2r0PNy7ULmK2qc12dh1noe9Dgv8NR4EeTpBs/XFWXqupLwGx3vRvdinuuqn+uqhe78dPA65PctC5Vr85qfs4keR/wJRZ63lAM+uW5vape6vb/Hbh9yJo7gPMDx3PdGMBHgI8D31izCsdvtT0DkOSNwE8Cn1mLIldpyfoH11TVFeA/gTeNeO6NaDU9D7of+HxVXVqjOsdpxT13N2m/BvzWOtQ5dpsnXcCNJsmnge8YMvXY4EFVVZKR301N8g7gu6rqVxZ/7jdpa9XzwPU3A38K/EFVnVtZlbrRJLkL+CjwnknXsg4+DPxeVb3S3eBvKAb9IlX1Y9ebS/IfSbZV1UtJtgFfGbLsAvDugePtwGeBdwK9JP/Gwr/7m5N8tqrezYStYc9XHQTOVtXvj6HctXAB2DFwvL0bG7ZmrvvF9e3AyyOeeyNaTc8k2Q58EvhAVb2w9uWOxWp6/gHgp5I8DrwR+GaS/6mqT6x92WMw6YcEG2kDPsa1DyYfH7LmVhY+x9vabV8Cbl20ZpqN8zB2VT2z8DziL4DXTbqX1+hxMwsPkHfyfw/p7lq05pe59iHdn3X7d3Htw9hzbIyHsavp+Y3d+vdPuo/16nnRmg+zwR7GTryAjbSx8PnkZ4CzwKcHwqwHPDmw7udZeCg3C3xwyHU2UtCvuGcW7pgKeB441W0PTbqn6/T5E8AXWXgr47Fu7ACwp9v/NhbetpgF/gl428C5j3XnneEGfKto3D0DvwH898DP9BTw5kn3s9Y/54FrbLig979AkKTG+daNJDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN+190y+s1mmA9ZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l3vixD4_YxE",
        "outputId": "6c8dde85-2bbc-41b2-b69f-bfb94a1d68df"
      },
      "source": [
        "thetas[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3651, -1.0659,  1.6011, -1.1961, -0.4254, -1.3957, -0.5281]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaSEzz7x_Vey"
      },
      "source": [
        "sim = qiskit.Aer.get_backend('qasm_simulator')\r\n",
        "\r\n",
        "test_circuit = QuantumCircuit(1, sim, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQd6iqoE_Ve3"
      },
      "source": [
        "test_circuit.run([-1.9])\r\n",
        "\r\n",
        "# test_circuit._circuit.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy111XeE_cm-",
        "outputId": "a00fc148-cdff-43f2-fc52-957a87ee6492"
      },
      "source": [
        "#Evaluation mode\r\n",
        "model.eval()\r\n",
        "#So it doesn't compute gradients\r\n",
        "with torch.no_grad():\r\n",
        "  correct = 0\r\n",
        "  #Go through the test loader\r\n",
        "  for image, label in test_loader:\r\n",
        "    #Get prediction\r\n",
        "    try:\r\n",
        "      prediction,theta = model(image)\r\n",
        "      #Get the index of the prediction (thus the true prediction of the image)\r\n",
        "      true_pred = prediction.argmax(dim=1, keepdim = True)\r\n",
        "      #If they're correct add em up\r\n",
        "      correct += true_pred.eq(label.view_as(true_pred)).sum().item()\r\n",
        "    except:\r\n",
        "      continue\r\n",
        "  \r\n",
        "  print(correct / len(test_loader) * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.84848484848486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpdbp6lopl3J"
      },
      "source": [
        "test_tensor = torch.tensor([ 0.0500,  0.0001,  0.1100,  0.0000,  0.0000, -0.1400,  0.0000, -0.0200])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61gxDeVV221g"
      },
      "source": [
        "test_tensor = [test_tensor]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "vCwLcK7_23sw",
        "outputId": "bc4b5dc7-4195-405f-a6f3-e1ce6da0f1d1"
      },
      "source": [
        "gradints = test_tensor.numpy()\r\n",
        "\r\n",
        "gradints = gradints.T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-df92cac4a348>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgradints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJrFVf_3rue"
      },
      "source": [
        "gradints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0I_ByO4P59"
      },
      "source": [
        "h = [[ 0.04374691, -0.08862904, -0.08470156, -0.07864326, -0.06539986, -0.0589257, 0.10701392]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta4_nNz5Jb0i",
        "outputId": "60bd6796-9523-4b7f-f872-929a7fcd8cd1"
      },
      "source": [
        "h[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04374691,\n",
              " -0.08862904,\n",
              " -0.08470156,\n",
              " -0.07864326,\n",
              " -0.06539986,\n",
              " -0.0589257,\n",
              " 0.10701392]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBWoEjkVJcUC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}