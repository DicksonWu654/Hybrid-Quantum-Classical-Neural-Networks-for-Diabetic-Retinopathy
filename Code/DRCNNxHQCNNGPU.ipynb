{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install qiskit","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import packages\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport path\n\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch.autograd import Function\nfrom torchvision import datasets, transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport qiskit\nfrom qiskit.visualization import *\nfrom qiskit import ClassicalRegister\n\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def target_to_oh(target):\n#     NUM_CLASS = 5  # hard code here, can do partial\n#     one_hot = torch.eye(NUM_CLASS)[target]\n#     return one_hot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_bunch = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),\n                                      transforms.RandomVerticalFlip(p=0.5),\n                                      transforms.RandomPerspective(),\n                                      transforms.RandomRotation(15),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize((0.5139, 0.2727, 0.0891), (0.1533, 0.0909, 0.0400))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ds = torchvision.datasets.ImageFolder(\"../input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images\", transform_bunch)#, target_transform = target_to_oh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in ds:\n    print(y)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"percent = 0.2\n\nsplit = int(len(ds) * percent)\n\nindices = list(range(len(ds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.shuffle(indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sampler = SubsetRandomSampler(indices[split:])\n\nvalid_sampler = SubsetRandomSampler(indices[:split])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 1\n\ndl = data.DataLoader(ds, bs, sampler=train_sampler)\n\nvalid_dl = data.DataLoader(ds, bs, sampler=valid_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xx = 0\nyy = 0\n\nfor x,y in valid_dl:\n    print(x.shape,y.shape)\n    xx = x\n    yy = y\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#looks like something is off... Yup --> We can just transform it at the end\nds.class_to_idx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"QC_outputs = ['000', '001', '010', '011', '100', '101', '110', '111']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defines the quantum circuit so we can use it (since hybrids have quantum)\nclass QuantumCircuit:\n  #This is the initialization\n  def __init__(self, n_qubits, backend, shots):\n    #Define how many lanes we want\n    self._circuit = qiskit.QuantumCircuit(n_qubits)\n\n    #Just a list of 0 to the number of qubits... Just useful so we can just define the circuit (with all it's little parts super quickly)\n    all_qubits = [i for i in range(n_qubits)]\n    #There are 7 placeholder variables\n    self.theta_0 = qiskit.circuit.Parameter('theta0')\n    self.theta_1 = qiskit.circuit.Parameter('theta1')\n    self.theta_2 = qiskit.circuit.Parameter('theta2')\n    self.theta_3 = qiskit.circuit.Parameter('theta3')\n    self.theta_4 = qiskit.circuit.Parameter('theta4')\n    self.theta_5 = qiskit.circuit.Parameter('theta5')\n    self.theta_6 = qiskit.circuit.Parameter('theta6')\n\n    #Shove in the Hardav gate, a barrier (visual), and a rotation about the y plane of theta degrees\n    self._circuit.h(all_qubits)\n    self._circuit.barrier()\n    self._circuit.ry(self.theta_0, all_qubits)\n    #Now comes the custom thing for 3 qubits specifically. I adapted it from a paper\n    self._circuit.cz(0,1)\n    self._circuit.cz(1,2)\n    self._circuit.ry(self.theta_1, 0)\n    self._circuit.ry(self.theta_2, 1)\n    self._circuit.ry(self.theta_3, 2)\n    self._circuit.cz(0,1)\n    self._circuit.cz(1,2)\n    self._circuit.ry(self.theta_4, 0)\n    self._circuit.ry(self.theta_5, 1)\n    self._circuit.ry(self.theta_6, 2)\n\n    self._circuit.measure_all()\n\n    #save these varaibles for later so we don't have to call them again during the forwarding\n    self.backend = backend\n    self.shots = shots\n  \n  #forwarding through the quantum circuit\n  def run(self, thetas):\n    #prep the execution. Link to circuit, Define backend and number of shots... And then fill in the placeholder variables (theta) with the thing we pass through when we forward\n    job = qiskit.execute(self._circuit,\n                         self.backend,\n                         shots = self.shots,\n                         parameter_binds = [{self.theta_0: thetas[0],\n                                             self.theta_1: thetas[1],\n                                             self.theta_2: thetas[2],\n                                             self.theta_3: thetas[3],\n                                             self.theta_4: thetas[4],\n                                             self.theta_5: thetas[5],\n                                             self.theta_6: thetas[6],}])\n    \n    #execution\n    counts = job.result().get_counts(self._circuit)\n\n    expects = np.zeros(8)\n    for k in range(8):\n      key = QC_outputs[k]\n      perc = counts.get(key, 0) /self.shots\n      expects[k] = perc\n    return expects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Going to test out the quantum circuit.\nsim = qiskit.Aer.get_backend('qasm_simulator')\n\ntest_circuit = QuantumCircuit(3, sim, 100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heck yeah it works! It outputs the distributions of the outputs\ntest_circuit.run([1,2,1,4,5,6,8]), test_circuit._circuit.draw()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This class defines what our hybrid layer does. It allows it to go forward, and also backprop\nclass HybridFunction(Function):\n\n  @staticmethod\n  def forward(ctx, input, quantum_circuit, shift):\n    ctx.shift = shift\n    ctx.quantum_circuit = quantum_circuit\n\n    parameter = []\n\n    #A very scrapy but functional way of loading the parameters in this format\n    for x in input:\n      for y in x:\n        parameter.append(float(y))\n    # print(parameter)\n\n    #Aka we run the input into our circuit\n    expectation_z = ctx.quantum_circuit.run(parameter) #Might need to change this when have multi-layer\n    #Shoves to pytorch tesnor\n    result = torch.tensor([expectation_z])\n    #Save the input and result for backpropagation\n    ctx.save_for_backward(input,result)\n    #return output\n    return result\n  \n  @staticmethod\n  def backward(ctx, grad_output):\n    #Regrabing the input and the output\n    input, expectation_z = ctx.saved_tensors\n    # input_list = np.array(input.tolist())\n    # print(input)\n\n    input_list = list(input)[0]\n    # print(input_list)\n\n    input_list = input_list.cpu()\n\n    #A list of all the gradients\n    gradients = torch.Tensor()\n\n    #We're going to go through the inputs and then calculate the gradient for each one\n    for i in range(7):\n      #In order to get the gradients for each one, we shift one of the parameters a tiny bit and find the difference in the outputs... Since we can't do backprop on it, we use something called shift parameter\n      shift_right = np.array(input_list.detach().clone())\n      shift_left = np.array(input_list.detach().clone())\n      shift_right[i] = shift_right[i] + ctx.shift\n      shift_left[i] = shift_left[i] - ctx.shift\n\n      #So we take the shifted ones and just compute it \n      expectation_right = ctx.quantum_circuit.run(shift_right)\n      expectation_left  = ctx.quantum_circuit.run(shift_left)\n      #Gradient = appox the difference (division by 2*shift isn't necessary since it'll just be a scaled version (which can be counteracted by lr))\n      gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n      #Append the gradient to the meta list\n      gradients  = torch.cat((gradients, gradient.float()))\n    \n    #Format everything\n    result = torch.Tensor(gradients)\n    result = result.float()\n    result = result.T\n\n    #Just a random varaible that made my life easier when debugging\n    Fixer = grad_output.float()\n    Fixer = Fixer.T\n\n    #Find the gradients at last!!!\n    h = result * Fixer\n    h = h.cuda()\n    #then return it for backprop\n    return h, None, None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This defines the acutal thing that we're shoving into the NN\nclass Hybrid(nn.Module):\n  #initialization\n  def __init__(self, backend, shots, shift):\n    super(Hybrid, self).__init__()\n    #Define the real quantum circuit that we'll be using for our thing\n    self.quantum_circuit = QuantumCircuit(3, backend, shots)\n    #Save this guy for alter\n    self.shift = shift\n  \n  #When forwarding\n  def forward(self, input):\n    return HybridFunction.apply(input, self.quantum_circuit, self.shift)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now I'll be making the model! It'll take elements off of nn.Module\nclass cnnmaker(nn.Module):\n    #Initialization will only take in input channels\n    def __init__(self, input_channels):\n        super().__init__()\n        \n        #I looked at what the resnet architechture looked like and just implmented the block types (not the residual part just yet)\n        def block(in_chan):\n            return nn.Sequential(nn.Conv2d(in_chan, in_chan * 3, 3, 2, 1, padding_mode = \"reflect\"),\n                                 nn.MaxPool2d(2),\n                                nn.ReLU())\n        \n        self.model = nn.Sequential(block(input_channels),\n                                   nn.Dropout(),\n                                   block(input_channels*3),\n                                   nn.Dropout(),\n                                   block(input_channels*9))\n        \n        self.second_model = nn.Sequential(nn.Linear(729, 250),\n                                         nn.Dropout(),\n                                         nn.ReLU(),\n                                         nn.Linear(250, 40),\n                                         nn.Dropout(),\n                                         nn.ReLU(),\n                                         nn.Linear(40, 7))\n        \n        self.quantum_model = Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 1000, np.pi / 2)\n        \n        self.end_model = nn.Sequential(\n            nn.Linear(8,5),\n            nn.Sigmoid()\n        )\n        \n    #The forward pass when you call it   \n    def forward(self, images):\n        pre_proc = self.model(images)\n#         print(pre_proc.shape)\n        \n        formatted = torch.reshape(pre_proc, (images.shape[0], -1))\n        \n        result = self.second_model(formatted)\n        \n        result = self.quantum_model(result)\n        \n        result = result.type(dtype=torch.cuda.FloatTensor)\n        result = self.end_model(result.float())\n        \n        result = result.view(1, -1)\n        \n        return torch.cat((result, 1-result), -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = cnnmaker(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at how many parameters\ntotal = 0\nfor param in model.parameters():\n    if param.requires_grad:\n        total += param.numel()\n\nprint(total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = model.to('cuda')\nloss_func = loss_func.to('cuda')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(preds, target):\n    correct = (preds == target).float()\n    accuracy = correct.sum() / len(correct)\n    return accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train():\n    model.train()\n    \n    for image, label in dl:\n        image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.LongTensor)\n        optimizer.zero_grad()\n        prediction = model(image)\n        \n        loss = loss_func(prediction, label)\n        \n        loss.backward()\n        \n        optimizer.step()\n    \n    with torch.no_grad():\n        total_iter = 0\n        total_acc = 0\n        for image, label in valid_dl: \n            image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.LongTensor)\n            prediction = model(image)\n            true_pred = prediction.argmax(dim=1, keepdim = True)\n            total_acc += true_pred.eq(label.view_as(true_pred)).sum().item()\n            total_iter += 1\n            if total_iter == 400:\n                print(\"valid\",total_acc/total_iter)\n                total_iter = 0\n                total_acc = 0\n                for image, label in dl: \n                    image, label = image.type(dtype=torch.cuda.FloatTensor), label.type(dtype=torch.cuda.LongTensor)\n                    prediction = model(image)\n                    true_pred = prediction.argmax(dim=1, keepdim = True)\n                    total_acc += true_pred.eq(label.view_as(true_pred)).sum().item()\n                    total_iter += 1\n                    if total_iter == 200:\n                        print(total_acc/total_iter)\n                        return \"done\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr = 0.003)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(4):\n    train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(10):\n    train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(20):\n    train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(20):\n    train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for _ in range(20):\n    train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xxx = 0\nyyy = 0\n\nfor x,y in dl:\n    print(x.shape,y.shape)\n    xxx = x\n    yyy = y\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yyy = yyy.type(dtype=torch.cuda.FloatTensor)\ntorch.argmax(yyy, dim = 1).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xxx = xxx.type(dtype=torch.cuda.FloatTensor)\nprediction = model(xxx)\ntorch.argmax(prediction, dim = 1).float()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy(torch.argmax(prediction, dim = 1).float(),torch.argmax(yyy, dim = 1).float())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with torch.no_grad():\n    total_iter = 0\n    total_acc = 0\n    for image, label in valid_dl: \n        image, label = image.to('cuda', dtype=torch.float), label.to('cuda', dtype=torch.float)\n        prediction = model(image)\n        true_pred = prediction.argmax(dim=1, keepdim = True)\n        total_acc += true_pred.eq(label.view_as(true_pred)).sum().item()\n#         print(label)\n#         print(true_pred)\n        total_iter += 1\n        if total_iter == 700:\n            print(total_acc/total_iter)\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dds = torchvision.datasets.ImageFolder(\"../input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images\", transform_bunch)#, target_transform = target_to_oh)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution = [0] * 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in dl:\n    distribution[y] = distribution[y] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"637+1805+295+193","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution[0][0] = distribution[0][0] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution[0] = [2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}