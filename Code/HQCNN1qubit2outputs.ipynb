{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QML-Hybrid.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9Jii2mfodcl",
        "outputId": "08a5825b-da79-41a4-d233-8fb5d08f90c7"
      },
      "source": [
        "!pip install qiskit;"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting qiskit\n",
            "  Downloading https://files.pythonhosted.org/packages/df/02/16212b2c01f2652c094bb865f2786d4e7a6206472898ee12137d98a85aca/qiskit-0.23.5.tar.gz\n",
            "Collecting qiskit-terra==0.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/e2/c256863ec8fab2162bf17d7e9c8564186a4636b4f24b5ea5d38a014b809e/qiskit_terra-0.16.4-cp36-cp36m-manylinux2010_x86_64.whl (8.5MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5MB 5.3MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/e0/9b28d7bd52cb6b2bc16b8e98b97e96dc7d22f5c40f91b529487b31526c8c/qiskit_aer-0.7.4-cp36-cp36m-manylinux2010_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 253kB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b9/f99bec4fdc4dec234d8a85a8da378750441a203c614be35353f5e8738316/qiskit_ibmq_provider-0.11.1-py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 47.6MB/s \n",
            "\u001b[?25hCollecting qiskit-ignis==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/1d/d5df8cf48cf20a26deb6e0535f020cd2ad625cb27457abb0ab39c2104e38/qiskit_ignis-0.5.2-py3-none-any.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 54.8MB/s \n",
            "\u001b[?25hCollecting qiskit-aqua==0.8.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/82/528741676960a7fd1c75151639601826118f2729ad53034fa3b39290c056/qiskit_aqua-0.8.2-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 48.1MB/s \n",
            "\u001b[?25hCollecting retworkx>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/5d4498cedb23927a31173176975e2162e0d6a2b80846ef254dd5500e10da/retworkx-0.7.2-cp36-cp36m-manylinux2010_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (5.4.8)\n",
            "Collecting sympy>=1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/69/b16fc81b939d3efdd0b552f2e3e54f7fa1423d0c320cced2e69e675dde26/sympy-1.7.1-py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (1.19.5)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (0.3.3)\n",
            "Collecting ply>=3.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/58/35da89ee790598a0700ea49b2a66594140f44dec458c07e8e3d4979137fc/ply-3.11-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hCollecting python-constraint>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/37/8b/5f1bc2734ca611943e1d6733ee244238679f6410a10cd45ede55a61a8402/python-constraint-1.4.0.tar.bz2\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.5)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (1.4.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.6/dist-packages (from qiskit-terra==0.16.4->qiskit) (2.6.0)\n",
            "Collecting contextvars>=2.4; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting fastjsonschema>=2.10\n",
            "  Downloading https://files.pythonhosted.org/packages/89/1c/8be51fa42aadc1c1611a52b866e1a5a1032a504f24789cf140b4e6d7c940/fastjsonschema-2.15.0-py3-none-any.whl\n",
            "Requirement already satisfied: cython>=0.27.1 in /usr/local/lib/python3.6/dist-packages (from qiskit-aer==0.7.4->qiskit) (0.29.21)\n",
            "Collecting pybind11>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/43/7339dbabbc2793718d59703aace4166f53c29ee1c202f6ff5bf8a26c4d91/pybind11-2.6.2-py2.py3-none-any.whl (191kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 45.0MB/s \n",
            "\u001b[?25hCollecting websockets>=8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio!=1.1.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (2.23.0)\n",
            "Collecting requests-ntlm>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/03/4b/8b9a1afde8072c4d5710d9fa91433d504325821b038e00237dc8d6d833dc/requests_ntlm-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from qiskit-ibmq-provider==0.11.1->qiskit) (1.24.3)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from qiskit-ignis==0.5.2->qiskit) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.6/dist-packages (from qiskit-ignis==0.5.2->qiskit) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (2.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (1.1.5)\n",
            "Collecting docplex==2.15.194\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/76/ebf5b75a25c4357c9a4758cae7fea778dd7f282b83c2f22e150dc7e3c852/docplex-2.15.194.tar.gz (582kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 34.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.8)\n",
            "Collecting quandl\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/58/9f0e69d836045e3865d263e9ed49f42b23a58526fdabb30f74c430baee3f/Quandl-3.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: fastdtw in /usr/local/lib/python3.6/dist-packages (from qiskit-aqua==0.8.2->qiskit) (0.3.4)\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Collecting dlx\n",
            "  Downloading https://files.pythonhosted.org/packages/54/c0/b8fb5bb727e983b6f5251433ef941b48f38c65bb0bd6ec509e9185bcd406/dlx-1.0.4.tar.gz\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy>=1.3->qiskit-terra==0.16.4->qiskit) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.8.0->qiskit-terra==0.16.4->qiskit) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->qiskit-terra==0.16.4->qiskit) (4.4.2)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/52/e64a14a99c509cbdfe0405e9f076aef0331cb9548a3efa1d5bacd524978a/immutables-0.15-cp36-cp36m-manylinux1_x86_64.whl (100kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.11.1->qiskit) (2.10)\n",
            "Collecting ntlm-auth>=1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/84/97c550164b54942b0e908c31ef09d9469f3ba4cd7332a671e2125732f63b/ntlm_auth-1.5.0-py2.py3-none-any.whl\n",
            "Collecting cryptography>=1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->qiskit-ignis==0.5.2->qiskit) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->qiskit-aqua==0.8.2->qiskit) (2018.9)\n",
            "Collecting inflection>=0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/59/91/aa6bde563e0085a02a435aa99b49ef75b0a4b062635e606dab23ce18d720/inflection-0.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from quandl->qiskit-aqua==0.8.2->qiskit) (8.7.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance->qiskit-aqua==0.8.2->qiskit) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/78/56a7c88a57d0d14945472535d0df9fb4bbad7d34ede658ec7961635c790e/lxml-4.6.2-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.11.1->qiskit) (2.20)\n",
            "Building wheels for collected packages: qiskit, python-constraint, contextvars, docplex, yfinance, dlx\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.23.5-cp36-none-any.whl size=2882 sha256=f2ca72f7616fedd93b245eff14136c9680abe650f678cb2db70dc6b13f086aa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/a7/8f/2720a308d16a991c6eba41517e8764158ea2c7856424112017\n",
            "  Building wheel for python-constraint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24079 sha256=6b56c2527d13ed07519514c74dbf06514f222908a71d8bd377d92853ea117888\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/31/15/7b070b25d0a549d20ce2e9fe6d727471c2c61ef904720fd40c\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7667 sha256=977e931d3fe3c7bdddf8e7c75944e5ccfd7e1d6062f74ffeb06ca041c7942a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "  Building wheel for docplex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docplex: filename=docplex-2.15.194-cp36-none-any.whl size=645116 sha256=3ccae4a79f3dbf67210166f601c89e52b4c93473e8b11bee5ea08546a2b2bdaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/fa/5d/8f4d5fed1b8edb72e453cb2ac6fb75c6776b49d7174eb70457\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22616 sha256=0d7befec7558e645ee698103a7d95d43b4d6d412dbf0a87e4506ce149c7b185a\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "  Building wheel for dlx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlx: filename=dlx-1.0.4-cp36-none-any.whl size=5711 sha256=9100df2d6a607afdabf14a54afe0f5009863f5a665d70482ff8dcd12e2bd5ae2\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/ba/15/fdd0deb104df3254912998150ba9245668db06b00af5912d1a\n",
            "Successfully built qiskit python-constraint contextvars docplex yfinance dlx\n",
            "Installing collected packages: retworkx, sympy, ply, python-constraint, immutables, contextvars, fastjsonschema, qiskit-terra, pybind11, qiskit-aer, websockets, ntlm-auth, cryptography, requests-ntlm, qiskit-ibmq-provider, qiskit-ignis, docplex, inflection, quandl, lxml, yfinance, dlx, qiskit-aqua, qiskit\n",
            "  Found existing installation: sympy 1.1.1\n",
            "    Uninstalling sympy-1.1.1:\n",
            "      Successfully uninstalled sympy-1.1.1\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed contextvars-2.4 cryptography-3.4.6 dlx-1.0.4 docplex-2.15.194 fastjsonschema-2.15.0 immutables-0.15 inflection-0.5.1 lxml-4.6.2 ntlm-auth-1.5.0 ply-3.11 pybind11-2.6.2 python-constraint-1.4.0 qiskit-0.23.5 qiskit-aer-0.7.4 qiskit-aqua-0.8.2 qiskit-ibmq-provider-0.11.1 qiskit-ignis-0.5.2 qiskit-terra-0.16.4 quandl-3.6.0 requests-ntlm-1.1.0 retworkx-0.7.2 sympy-1.7.1 websockets-8.1 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E61VulyirRGK"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch.autograd import Function\r\n",
        "from torchvision import datasets, transforms\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import qiskit\r\n",
        "from qiskit.visualization import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-3MTFuvrdQJ"
      },
      "source": [
        "# Defines the quantum circuit so we can use it (since hybrids have quantum)\r\n",
        "class QuantumCircuit:\r\n",
        "  #This is the initialization\r\n",
        "  def __init__(self, n_qubits, backend, shots):\r\n",
        "    #Define how many lanes we want\r\n",
        "    self._circuit = qiskit.QuantumCircuit(n_qubits)\r\n",
        "\r\n",
        "    #Just a list of 0 to the number of qubits... Just useful so we can just define the circuit (with all it's little parts super quickly)\r\n",
        "    all_qubits = [i for i in range(n_qubits)]\r\n",
        "    #Kind of like a placeholder variable so we can fill it in later\r\n",
        "    self.theta = qiskit.circuit.Parameter('theta') #Change when multi\r\n",
        "\r\n",
        "    #Shove in the Hardav gate, a barrier (visual), and a rotation about the y plane of theta degrees\r\n",
        "    self._circuit.h(all_qubits)\r\n",
        "    self._circuit.barrier()\r\n",
        "    self._circuit.ry(self.theta, all_qubits) #Change when multi\r\n",
        "\r\n",
        "    self._circuit.measure_all()\r\n",
        "\r\n",
        "    #save these varaibles for later so we don't have to call them again during the forwarding\r\n",
        "    self.backend = backend\r\n",
        "    self.shots = shots\r\n",
        "  \r\n",
        "  #forwarding through the quantum circuit\r\n",
        "  def run(self, thetas):\r\n",
        "    #prep the execution. Link to circuit, Define backend and number of shots... And then fill in the placeholder variable (theta) with the thing we pass through when we forward\r\n",
        "    job = qiskit.execute(self._circuit,\r\n",
        "                         self.backend,\r\n",
        "                         shots = self.shots,\r\n",
        "                         parameter_binds = [{self.theta: theta} for theta in thetas]) # Might have to change this when multi layer\r\n",
        "    \r\n",
        "    #execution\r\n",
        "    result = job.result().get_counts(self._circuit)\r\n",
        "\r\n",
        "    #Counts = number of occurances (for each state)\r\n",
        "    counts = np.array(list(result.values()))\r\n",
        "    \r\n",
        "    #States=  States of the occuraces (like 001, 101, 110 etc)\r\n",
        "    states = np.array(list(result.keys())).astype(float)\r\n",
        "\r\n",
        "    #This just brings it down to the percentage that this particular state occurs\r\n",
        "    prob = counts / self.shots\r\n",
        "\r\n",
        "    #AKA what the average of this circuit does\r\n",
        "    expect = np.sum(states * prob)\r\n",
        "    #Returns as an array\r\n",
        "    return np.array([expect])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toApC567z76D"
      },
      "source": [
        "sim = qiskit.Aer.get_backend('qasm_simulator')\r\n",
        "\r\n",
        "test_circuit = QuantumCircuit(1, sim, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "HKZ-V5ek0Kqm",
        "outputId": "9058b1ab-0552-4acd-b429-6985fd1a8bd5"
      },
      "source": [
        "test_circuit.run([3/2])\r\n",
        "\r\n",
        "test_circuit._circuit.draw()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "   q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 </pre>"
            ],
            "text/plain": [
              "        ┌───┐ ░ ┌───────────┐ ░ ┌─┐\n",
              "   q_0: ┤ H ├─░─┤ RY(theta) ├─░─┤M├\n",
              "        └───┘ ░ └───────────┘ ░ └╥┘\n",
              "meas: 1/═════════════════════════╩═\n",
              "                                 0 "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aVKFvxS0PPZ"
      },
      "source": [
        "#This class defines what our hybrid layer does. It allows it to go forward, and also backprop\r\n",
        "class HybridFunction(Function):\r\n",
        "\r\n",
        "  @staticmethod\r\n",
        "  def forward(ctx, input, quantum_circuit, shift):\r\n",
        "    ctx.shift = shift\r\n",
        "    ctx.quantum_circuit = quantum_circuit\r\n",
        "\r\n",
        "    #Aka we run the input into our circuit\r\n",
        "    expectation_z = ctx.quantum_circuit.run(input[0].tolist()) #Might need to change this when have multi-layer\r\n",
        "    #Shoves to pytorch tesnor\r\n",
        "    result = torch.tensor([expectation_z])\r\n",
        "    #Save the input and result for backpropagation\r\n",
        "    ctx.save_for_backward(input,result)\r\n",
        "    #return output\r\n",
        "    return result\r\n",
        "  \r\n",
        "  @staticmethod\r\n",
        "  def backward(ctx, grad_output):\r\n",
        "    #Regrabing the input and the output\r\n",
        "    input, expectation_z = ctx.saved_tensors\r\n",
        "    input_list = np.array(input.tolist())\r\n",
        "\r\n",
        "    #AKA if we take our inputs and just add/subtract a tiny amount\r\n",
        "    shift_right = input_list + np.ones(input_list.shape) * ctx.shift\r\n",
        "    shift_left = input_list - np.ones(input_list.shape) * ctx.shift\r\n",
        "\r\n",
        "    #A list of all the gradients\r\n",
        "    gradients = []\r\n",
        "\r\n",
        "    #We're going to go through the inputs and then calculate the gradient for each one\r\n",
        "    for i in range(len(input_list)):\r\n",
        "      #So we take the shifted ones and just compute it \r\n",
        "      expectation_right = ctx.quantum_circuit.run(shift_right[i])\r\n",
        "      expectation_left  = ctx.quantum_circuit.run(shift_left[i])\r\n",
        "      #Gradient = appox the difference (division by 2*shift isn't necessary since it'll just be a scaled version (which can be counteracted by lr))\r\n",
        "      gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\r\n",
        "      #Append the gradient to the meta list\r\n",
        "      gradients.append(gradient)\r\n",
        "    \r\n",
        "    #Turn it into np and transpose it\r\n",
        "    gradients = np.array([gradients]).T\r\n",
        "    #then return it for backprop\r\n",
        "    print(gradients)\r\n",
        "    print(torch.tensor([gradients]).float() * grad_output.float(), None, None)\r\n",
        "    return torch.tensor([gradients]).float() * grad_output.float(), None, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv5A7QC8ul2R"
      },
      "source": [
        "#This defines the acutal thing that we're shoving into the NN\r\n",
        "class Hybrid(nn.Module):\r\n",
        "  #initialization\r\n",
        "  def __init__(self, backend, shots, shift):\r\n",
        "    super(Hybrid, self).__init__()\r\n",
        "    #Define the real quantum circuit that we'll be using for our thing\r\n",
        "    self.quantum_circuit = QuantumCircuit(1, backend, shots)\r\n",
        "    #Save this guy for alter\r\n",
        "    self.shift = shift\r\n",
        "  \r\n",
        "  #When forwarding\r\n",
        "  def forward(self, input):\r\n",
        "    return HybridFunction.apply(input, self.quantum_circuit, self.shift)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrvo6muavKEb"
      },
      "source": [
        "#Now we just define the data stuff\r\n",
        "\r\n",
        "n_samples = 1000\r\n",
        "\r\n",
        "X_train = datasets.MNIST(root='./data', train=True, download=True,\r\n",
        "                         transform=transforms.Compose([transforms.ToTensor()]))\r\n",
        "\r\n",
        "# Leaving only labels 0 and 1 \r\n",
        "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \r\n",
        "                np.where(X_train.targets == 1)[0][:n_samples])\r\n",
        "\r\n",
        "X_train.data = X_train.data[idx]\r\n",
        "X_train.targets = X_train.targets[idx]\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_NW21jbvWmb"
      },
      "source": [
        "n_samples = 1000\r\n",
        "\r\n",
        "X_test = datasets.MNIST(root='./data', train=False, download=True,\r\n",
        "                        transform=transforms.Compose([transforms.ToTensor()]))\r\n",
        "\r\n",
        "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \r\n",
        "                np.where(X_test.targets == 1)[0][:n_samples])\r\n",
        "\r\n",
        "X_test.data = X_test.data[idx]\r\n",
        "X_test.targets = X_test.targets[idx]\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DaX_00tvZt0"
      },
      "source": [
        "#The actual one\r\n",
        "class Net(nn.Module):\r\n",
        "  #Initialization\r\n",
        "  def __init__(self):\r\n",
        "    super(Net, self).__init__()\r\n",
        "    #Defining all the classical layers\r\n",
        "    self.classical = nn.Sequential(\r\n",
        "        nn.Conv2d(1,6,5),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2),\r\n",
        "        nn.Conv2d(6,16,5),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2),\r\n",
        "        nn.Dropout()\r\n",
        "    )\r\n",
        "    #Defining the middel part\r\n",
        "    self.middel = nn.Sequential(\r\n",
        "        nn.Linear(256,64),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(64,1))\r\n",
        "    #Definign the quantum part\r\n",
        "    self.quantum = Hybrid(qiskit.Aer.get_backend('qasm_simulator'), 100, np.pi / 2)\r\n",
        "  \r\n",
        "  #For whenever we pass stuff through it\r\n",
        "  def forward(self,x):\r\n",
        "    #Pass it through each one\r\n",
        "    x = self.classical(x)\r\n",
        "    x = x.view(1, -1)\r\n",
        "    x = self.middel(x)\r\n",
        "    theta = x\r\n",
        "    x = self.quantum(x)\r\n",
        "    return torch.cat((x,1-x), -1), theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjfzokPbzrYr"
      },
      "source": [
        "#Define the model, optimzier and loss function\r\n",
        "model = Net()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "loss_func = nn.NLLLoss()\r\n",
        "\r\n",
        "#Define the epochs and the list (where we plot) the losses\r\n",
        "epochs = 5\r\n",
        "loss_list = []\r\n",
        "thetas = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Pmy5Eh710GPj",
        "outputId": "28241fa0-769e-4500-8216-19a643aeb0b8"
      },
      "source": [
        "#Training mode\r\n",
        "model.train()\r\n",
        "for epoch in range(epochs):\r\n",
        "  #So we can shove it on the loss graph\r\n",
        "  total_loss = []\r\n",
        "  #Go through the dataloader\r\n",
        "  for image, label in train_loader:\r\n",
        "    #Set the gradient back to 0\r\n",
        "    optimizer.zero_grad()\r\n",
        "    #Shove the image through the model\r\n",
        "    prediction,theta = model(image)\r\n",
        "    #Get the loss\r\n",
        "    loss = loss_func(prediction, label)\r\n",
        "    #Compute the gradients\r\n",
        "    loss.backward()\r\n",
        "    #Update parameters\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    #Save theta\r\n",
        "    thetas.append(theta)\r\n",
        "    #Add this loss to the total\r\n",
        "    total_loss.append(loss.item())\r\n",
        "  \r\n",
        "  #Shove total loss of epoch to the total loss of the model\r\n",
        "  loss_list.append(sum(total_loss) / len(total_loss))\r\n",
        "  #Print some readout so we know it's working\r\n",
        "  print(loss_list[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]\n",
            "tensor([[[-1.]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[-0.9900]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[-0.9900]]]) None None\n",
            "[[0.97]]\n",
            "tensor([[[0.9700]]]) None None\n",
            "[[0.97]]\n",
            "tensor([[[-0.9700]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[-0.9800]]]) None None\n",
            "[[0.93]]\n",
            "tensor([[[0.9300]]]) None None\n",
            "[[0.96]]\n",
            "tensor([[[-0.9600]]]) None None\n",
            "[[0.96]]\n",
            "tensor([[[0.9600]]]) None None\n",
            "[[0.93]]\n",
            "tensor([[[-0.9300]]]) None None\n",
            "[[0.96]]\n",
            "tensor([[[0.9600]]]) None None\n",
            "[[0.96]]\n",
            "tensor([[[0.9600]]]) None None\n",
            "[[0.92]]\n",
            "tensor([[[-0.9200]]]) None None\n",
            "[[0.87]]\n",
            "tensor([[[-0.8700]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.96]]\n",
            "tensor([[[0.9600]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.89]]\n",
            "tensor([[[-0.8900]]]) None None\n",
            "[[0.77]]\n",
            "tensor([[[-0.7700]]]) None None\n",
            "[[0.95]]\n",
            "tensor([[[0.9500]]]) None None\n",
            "[[0.76]]\n",
            "tensor([[[-0.7600]]]) None None\n",
            "[[0.97]]\n",
            "tensor([[[0.9700]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[0.9900]]]) None None\n",
            "[[0.97]]\n",
            "tensor([[[0.9700]]]) None None\n",
            "[[1.]]\n",
            "tensor([[[1.]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[0.9900]]]) None None\n",
            "[[1.]]\n",
            "tensor([[[1.]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[0.9900]]]) None None\n",
            "[[0.87]]\n",
            "tensor([[[-0.8700]]]) None None\n",
            "[[0.77]]\n",
            "tensor([[[-0.7700]]]) None None\n",
            "[[1.]]\n",
            "tensor([[[1.]]]) None None\n",
            "[[0.93]]\n",
            "tensor([[[-0.9300]]]) None None\n",
            "[[1.]]\n",
            "tensor([[[1.]]]) None None\n",
            "[[1.]]\n",
            "tensor([[[1.]]]) None None\n",
            "[[0.89]]\n",
            "tensor([[[-0.8900]]]) None None\n",
            "[[0.66]]\n",
            "tensor([[[-0.6600]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.88]]\n",
            "tensor([[[0.8800]]]) None None\n",
            "[[0.45]]\n",
            "tensor([[[-0.4500]]]) None None\n",
            "[[0.93]]\n",
            "tensor([[[0.9300]]]) None None\n",
            "[[0.39]]\n",
            "tensor([[[-0.3900]]]) None None\n",
            "[[0.98]]\n",
            "tensor([[[0.9800]]]) None None\n",
            "[[0.84]]\n",
            "tensor([[[0.8400]]]) None None\n",
            "[[0.88]]\n",
            "tensor([[[0.8800]]]) None None\n",
            "[[0.81]]\n",
            "tensor([[[0.8100]]]) None None\n",
            "[[0.45]]\n",
            "tensor([[[-0.4500]]]) None None\n",
            "[[0.68]]\n",
            "tensor([[[-0.6800]]]) None None\n",
            "[[0.27]]\n",
            "tensor([[[-0.2700]]]) None None\n",
            "[[-0.03]]\n",
            "tensor([[[-0.0300]]]) None None\n",
            "[[-0.17]]\n",
            "tensor([[[0.1700]]]) None None\n",
            "[[0.19]]\n",
            "tensor([[[0.1900]]]) None None\n",
            "[[-0.78]]\n",
            "tensor([[[0.7800]]]) None None\n",
            "[[0.5]]\n",
            "tensor([[[0.5000]]]) None None\n",
            "[[0.61]]\n",
            "tensor([[[0.6100]]]) None None\n",
            "[[0.16]]\n",
            "tensor([[[0.1600]]]) None None\n",
            "[[-0.26]]\n",
            "tensor([[[-0.2600]]]) None None\n",
            "[[0.35]]\n",
            "tensor([[[0.3500]]]) None None\n",
            "[[0.35]]\n",
            "tensor([[[-0.3500]]]) None None\n",
            "[[-0.33]]\n",
            "tensor([[[-0.3300]]]) None None\n",
            "[[0.91]]\n",
            "tensor([[[-0.9100]]]) None None\n",
            "[[-0.27]]\n",
            "tensor([[[0.2700]]]) None None\n",
            "[[-0.31]]\n",
            "tensor([[[-0.3100]]]) None None\n",
            "[[0.99]]\n",
            "tensor([[[-0.9900]]]) None None\n",
            "[[-0.96]]\n",
            "tensor([[[0.9600]]]) None None\n",
            "[[0.8]]\n",
            "tensor([[[-0.8000]]]) None None\n",
            "[[0.74]]\n",
            "tensor([[[-0.7400]]]) None None\n",
            "[[0.2]]\n",
            "tensor([[[0.2000]]]) None None\n",
            "[[-0.45]]\n",
            "tensor([[[0.4500]]]) None None\n",
            "[[0.63]]\n",
            "tensor([[[0.6300]]]) None None\n",
            "[[0.09]]\n",
            "tensor([[[0.0900]]]) None None\n",
            "[[0.31]]\n",
            "tensor([[[0.3100]]]) None None\n",
            "[[0.26]]\n",
            "tensor([[[0.2600]]]) None None\n",
            "[[0.14]]\n",
            "tensor([[[-0.1400]]]) None None\n",
            "[[0.85]]\n",
            "tensor([[[-0.8500]]]) None None\n",
            "[[0.41]]\n",
            "tensor([[[0.4100]]]) None None\n",
            "[[-0.03]]\n",
            "tensor([[[0.0300]]]) None None\n",
            "[[-0.84]]\n",
            "tensor([[[0.8400]]]) None None\n",
            "[[-0.45]]\n",
            "tensor([[[0.4500]]]) None None\n",
            "[[0.37]]\n",
            "tensor([[[-0.3700]]]) None None\n",
            "[[0.24]]\n",
            "tensor([[[0.2400]]]) None None\n",
            "[[0.91]]\n",
            "tensor([[[-0.9100]]]) None None\n",
            "[[-0.17]]\n",
            "tensor([[[0.1700]]]) None None\n",
            "[[0.25]]\n",
            "tensor([[[0.2500]]]) None None\n",
            "[[0.64]]\n",
            "tensor([[[-0.6400]]]) None None\n",
            "[[0.27]]\n",
            "tensor([[[0.2700]]]) None None\n",
            "[[-0.72]]\n",
            "tensor([[[-0.7200]]]) None None\n",
            "[[-0.61]]\n",
            "tensor([[[0.6100]]]) None None\n",
            "[[-0.04]]\n",
            "tensor([[[0.0400]]]) None None\n",
            "[[-0.66]]\n",
            "tensor([[[-0.6600]]]) None None\n",
            "[[0.57]]\n",
            "tensor([[[-0.5700]]]) None None\n",
            "[[-0.23]]\n",
            "tensor([[[0.2300]]]) None None\n",
            "[[-0.7]]\n",
            "tensor([[[0.7000]]]) None None\n",
            "[[-0.02]]\n",
            "tensor([[[0.0200]]]) None None\n",
            "[[0.13]]\n",
            "tensor([[[0.1300]]]) None None\n",
            "[[-0.39]]\n",
            "tensor([[[0.3900]]]) None None\n",
            "[[0.57]]\n",
            "tensor([[[0.5700]]]) None None\n",
            "[[0.26]]\n",
            "tensor([[[-0.2600]]]) None None\n",
            "[[-0.13]]\n",
            "tensor([[[0.1300]]]) None None\n",
            "[[0.31]]\n",
            "tensor([[[-0.3100]]]) None None\n",
            "[[0.69]]\n",
            "tensor([[[0.6900]]]) None None\n",
            "[[0.77]]\n",
            "tensor([[[0.7700]]]) None None\n",
            "[[0.36]]\n",
            "tensor([[[0.3600]]]) None None\n",
            "[[0.89]]\n",
            "tensor([[[-0.8900]]]) None None\n",
            "[[0.64]]\n",
            "tensor([[[-0.6400]]]) None None\n",
            "[[0.38]]\n",
            "tensor([[[0.3800]]]) None None\n",
            "[[0.81]]\n",
            "tensor([[[0.8100]]]) None None\n",
            "[[-0.32]]\n",
            "tensor([[[0.3200]]]) None None\n",
            "[[0.25]]\n",
            "tensor([[[0.2500]]]) None None\n",
            "[[-0.63]]\n",
            "tensor([[[0.6300]]]) None None\n",
            "[[0.16]]\n",
            "tensor([[[-0.1600]]]) None None\n",
            "[[-0.48]]\n",
            "tensor([[[0.4800]]]) None None\n",
            "[[0.09]]\n",
            "tensor([[[0.0900]]]) None None\n",
            "[[-0.04]]\n",
            "tensor([[[0.0400]]]) None None\n",
            "[[0.05]]\n",
            "tensor([[[0.0500]]]) None None\n",
            "[[0.23]]\n",
            "tensor([[[-0.2300]]]) None None\n",
            "[[0.25]]\n",
            "tensor([[[-0.2500]]]) None None\n",
            "[[-0.33]]\n",
            "tensor([[[-0.3300]]]) None None\n",
            "[[0.3]]\n",
            "tensor([[[0.3000]]]) None None\n",
            "[[0.76]]\n",
            "tensor([[[-0.7600]]]) None None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-45c1bbb40ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#Shove the image through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Get the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-20ac53f2a04f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-5aa618bf8e71>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m#When forwarding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHybridFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_circuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-91ed79ae8b2e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, quantum_circuit, shift)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Aka we run the input into our circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mexpectation_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_circuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Might need to change this when have multi-layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Shoves to pytorch tesnor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexpectation_z\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-f4f12870f76a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     28\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                          \u001b[0mshots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                          parameter_binds = [{self.theta: theta} for theta in thetas]) # Might have to change this when multi layer\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/qiskit/execute.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(experiments, backend, basis_gates, coupling_map, backend_properties, initial_layout, seed_transpiler, optimization_level, pass_manager, qobj_id, qobj_header, shots, memory, max_credits, seed_simulator, default_qubit_los, default_meas_los, schedule_los, meas_level, meas_return, memory_slots, memory_slot_size, rep_time, rep_delay, parameter_binds, schedule_circuit, inst_map, meas_map, scheduling_method, init_qubits, **run_config)\u001b[0m\n\u001b[1;32m    287\u001b[0m                         \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                         \u001b[0minit_qubits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_qubits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m                         **run_config)\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# executing the circuits on the backend and returning the job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/qiskit/compiler/assemble.py\u001b[0m in \u001b[0;36massemble\u001b[0;34m(experiments, backend, qobj_id, qobj_header, shots, memory, max_credits, seed_simulator, qubit_lo_freq, meas_lo_freq, qubit_lo_range, meas_lo_range, schedule_los, meas_level, meas_return, meas_map, memory_slot_size, rep_time, rep_delay, parameter_binds, parametric_pulses, init_qubits, **run_config)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                                                       \u001b[0mshots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_credits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                                                       \u001b[0mseed_simulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_qubits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                                                       rep_delay, **run_config)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# assemble either circuits or schedules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/qiskit/compiler/assemble.py\u001b[0m in \u001b[0;36m_parse_common_args\u001b[0;34m(backend, qobj_id, qobj_header, shots, memory, max_credits, seed_simulator, init_qubits, rep_delay, **run_config)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0mqobj_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQobjHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqobj_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mmax_shots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_shots'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshots\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_shots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M30HrQv0cor"
      },
      "source": [
        "plt.plot(thetas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l3vixD4_YxE"
      },
      "source": [
        "thetas[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaSEzz7x_Vey"
      },
      "source": [
        "sim = qiskit.Aer.get_backend('qasm_simulator')\r\n",
        "\r\n",
        "test_circuit = QuantumCircuit(1, sim, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQd6iqoE_Ve3"
      },
      "source": [
        "test_circuit.run([-1.9])\r\n",
        "\r\n",
        "# test_circuit._circuit.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy111XeE_cm-"
      },
      "source": [
        "#Evaluation mode\r\n",
        "model.eval()\r\n",
        "#So it doesn't compute gradients\r\n",
        "with torch.no_grad():\r\n",
        "  correct = 0\r\n",
        "  #Go through the test loader\r\n",
        "  for image, label in test_loader:\r\n",
        "    #Get prediction\r\n",
        "    prediction,theta = model(image)\r\n",
        "    #Get the index of the prediction (thus the true prediction of the image)\r\n",
        "    true_pred = prediction.argmax(dim=1, keepdim = True)\r\n",
        "    #If they're correct add em up\r\n",
        "    correct += true_pred.eq(label.view_as(true_pred)).sum().item()\r\n",
        "  \r\n",
        "  print(correct / len(test_loader) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSDGXcpqFJS7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}